"""
Prepare the Kaggle dataset into the exact structure expected by this repo:

project_root/
└── dataset/
    ├── images/{train,val}/
    ├── labels/{train,val}/
    └── data.yaml

This script is tailored to the chosen Kaggle dataset:
https://www.kaggle.com/datasets/snehilsanyal/construction-site-safety-image-dataset-roboflow

That dataset has 10 classes. We keep ONLY:
  - Hardhat      -> helmet (new class id 0)
  - Safety Vest  -> vest   (new class id 1)
  - Person       -> person (new class id 2)

All other labels are removed (their boxes are dropped).
"""

from __future__ import annotations

import argparse
import shutil
from pathlib import Path


# Original dataset class ids (from the Kaggle data card):
# {0: 'Hardhat', 1: 'Mask', 2: 'NO-Hardhat', 3: 'NO-Mask', 4: 'NO-Safety Vest',
#  5: 'Person', 6: 'Safety Cone', 7: 'Safety Vest', 8: 'machinery', 9: 'vehicle'}
KEEP_AND_REMAP = {
    0: 0,  # Hardhat -> helmet
    7: 1,  # Safety Vest -> vest
    5: 2,  # Person -> person
}

IMAGE_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}


def _find_dataset_root(kaggle_extract_dir: Path) -> Path:
    """
    Kaggle zip typically contains a top-level 'css-data' folder.
    Accept either the extracted root or the nested folder.
    """
    if (kaggle_extract_dir / "css-data").is_dir():
        return kaggle_extract_dir / "css-data"
    return kaggle_extract_dir


def _iter_images(images_dir: Path) -> list[Path]:
    if not images_dir.is_dir():
        return []
    return sorted([p for p in images_dir.iterdir() if p.suffix.lower() in IMAGE_EXTS])


def _filter_and_remap_label(src_label: Path, dst_label: Path) -> None:
    """
    Read YOLO label file, keep only selected class IDs, remap to 0..2.
    If src_label doesn't exist, we create an empty dst_label (background image).
    """
    dst_label.parent.mkdir(parents=True, exist_ok=True)

    if not src_label.exists():
        dst_label.write_text("", encoding="utf-8")
        return

    out_lines: list[str] = []
    for raw in src_label.read_text(encoding="utf-8").splitlines():
        line = raw.strip()
        if not line:
            continue

        parts = line.split()
        if len(parts) != 5:
            # Skip malformed rows instead of crashing; verify script will catch it later.
            continue

        try:
            cls = int(float(parts[0]))
        except ValueError:
            continue

        if cls not in KEEP_AND_REMAP:
            continue

        new_cls = KEEP_AND_REMAP[cls]
        # Keep coords as-is (already normalized YOLO format in this dataset)
        out_lines.append(" ".join([str(new_cls)] + parts[1:]))

    dst_label.write_text("\n".join(out_lines) + ("\n" if out_lines else ""), encoding="utf-8")


def _copy_split(dataset_root: Path, split_in: str, split_out: str, out_root: Path) -> None:
    in_split_dir = dataset_root / split_in
    images_in = in_split_dir / "images"
    labels_in = in_split_dir / "labels"

    imgs = _iter_images(images_in)
    if not imgs:
        raise FileNotFoundError(
            f"No images found in: {images_in}. "
            f"Expected Roboflow-style folder: {split_in}/images/"
        )

    images_out = out_root / "images" / split_out
    labels_out = out_root / "labels" / split_out
    images_out.mkdir(parents=True, exist_ok=True)
    labels_out.mkdir(parents=True, exist_ok=True)

    for img_path in imgs:
        dst_img = images_out / img_path.name
        shutil.copy2(img_path, dst_img)

        src_label = labels_in / f"{img_path.stem}.txt"
        dst_label = labels_out / f"{img_path.stem}.txt"
        _filter_and_remap_label(src_label, dst_label)


def _write_data_yaml(out_root: Path) -> None:
    yaml_text = """# Auto-generated by src/prepare_dataset.py
path: dataset
train: images/train
val: images/val

names:
  0: helmet
  1: vest
  2: person
"""
    (out_root / "data.yaml").write_text(yaml_text, encoding="utf-8")


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument(
        "--kaggle_dir",
        type=str,
        required=True,
        help="Path to the extracted Kaggle dataset directory (zip extracted folder).",
    )
    ap.add_argument(
        "--out_dir",
        type=str,
        default="dataset",
        help="Output dataset directory (default: dataset).",
    )
    args = ap.parse_args()

    kaggle_dir = Path(args.kaggle_dir).expanduser().resolve()
    out_dir = Path(args.out_dir).expanduser().resolve()

    dataset_root = _find_dataset_root(kaggle_dir)
    if not dataset_root.is_dir():
        raise FileNotFoundError(f"Dataset root not found: {dataset_root}")

    # Start clean to keep the output reproducible.
    (out_dir / "images" / "train").mkdir(parents=True, exist_ok=True)
    (out_dir / "images" / "val").mkdir(parents=True, exist_ok=True)
    (out_dir / "labels" / "train").mkdir(parents=True, exist_ok=True)
    (out_dir / "labels" / "val").mkdir(parents=True, exist_ok=True)

    # Roboflow exports commonly use: train / valid / test
    _copy_split(dataset_root, split_in="train", split_out="train", out_root=out_dir)
    _copy_split(dataset_root, split_in="valid", split_out="val", out_root=out_dir)

    _write_data_yaml(out_dir)
    print(f"[OK] Prepared dataset at: {out_dir}")
    print("[OK] Classes: 0=helmet, 1=vest, 2=person")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

